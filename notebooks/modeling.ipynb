{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letterboxd Analysis Project: Modeling\n",
    "\n",
    "**Author:** Sierra Stanton\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Theater Scene](../images/zach-galifianakis-math.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll initially determine a simple recommendation model and iteratively build on our efforts to improve the film recommendations for Letterboxd users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard import\n",
    "import pandas as pd\n",
    "\n",
    "# import needed surprise libraries\n",
    "from surprise import Reader, Dataset, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.prediction_algorithms import SVD, KNNWithMeans, KNNBasic\n",
    "\n",
    "# retrieve dataframe as pickle file\n",
    "import pickle\n",
    "df = pickle.load(open(\"df.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating_val</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happiest-season</td>\n",
       "      <td>8</td>\n",
       "      <td>deathproof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happiest-season</td>\n",
       "      <td>7</td>\n",
       "      <td>davidehrlich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happiest-season</td>\n",
       "      <td>4</td>\n",
       "      <td>ingridgoeswest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happiest-season</td>\n",
       "      <td>7</td>\n",
       "      <td>silentdawn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>happiest-season</td>\n",
       "      <td>2</td>\n",
       "      <td>colonelmortimer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          movie_id  rating_val          user_id\n",
       "0  happiest-season           8       deathproof\n",
       "1  happiest-season           7     davidehrlich\n",
       "2  happiest-season           4   ingridgoeswest\n",
       "3  happiest-season           7       silentdawn\n",
       "4  happiest-season           2  colonelmortimer"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure our resulting dataset is brought in for modeling\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've verified that the data we feed into our read has the following required Surprise columns present: `user ; item ; rating ;`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our modeling, we choose to use the __[Surprise library](https://surprise.readthedocs.io/en/stable/index.html)__, a Python sci-kit for recommender systems. The library contains built in algorithms and cross-validation methods we can use to make an increasingly proficient model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read in values as surprise dataset\n",
    "reader = Reader(rating_scale=(1,10), line_format=('item rating user'))\n",
    "data = Dataset.load_from_df(df[['user_id', 'movie_id', 'rating_val']],reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "train, test = train_test_split(data, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.trainset.Trainset at 0x7f934d69fe80>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run our first model: KNNBasic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the Surprise library, `KNNBasic` will give us a basic collaborative filtering algorithm to start with. Let's see how our data starts performing with these algorithms so we can continue fine tuning and get the best recommendations possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Nearest Nieghbor methods are memory or neighbor-based so they're typically good as baselines. Because this method find the level of similarity between a user and every other user to make a prediction (according to the weighted average) - there are two things we want to take into account based on what we know about our data.\n",
    "\n",
    "One is the cold start problem - because without initial information on the user's preferences we can't make an adaquate comparison. Two is the tendency toward popularity bias. If a particular item is often rated 5 stars across the board, our prediction would likely be about 5 stars even if our user happens to have a difference in taste from the popular opinion. We know that our film data skews toward more recent years so this is worth noting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way we gauge similarity from user to user can be altered. Since pearson is noted to most often be the best performing for rec engines, that's where we'll start in our baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚è∞ NOTE: Because a few of these models can be exahustive and take time to run, I'll comment out the code below with the accompanying results in order to showcase development and aid anyone who'd like to follow suit. Simply uncomment if you'd like to run them yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sim_options = {'name': 'cosine'}\n",
    "algo_knn_basic = KNNBasic(sim_options=sim_options)\n",
    "predictions = algo_knn_basic.fit(train).test(test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESULTS**\n",
    "* RMSE = 1.5951053223214062"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what if we change the similarity matrix to cosine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sim_options = {'name': 'pearson'}\n",
    "algo_knn_basic = KNNBasic(sim_options=sim_options)\n",
    "predictions = algo_knn_basic.fit(train).test(test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESULTS**\n",
    "* RMSE 1.5884529441409094"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Baseline Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### So, what exactly does our RMSE tell us?\n",
    "\n",
    "Our RMSE shows us the typical amount our model prediction differs from the actual rating a user would give by comparing our predictions with our test data for accuracy.\n",
    "\n",
    "Since our best performing model so far has a 1.4899 RMSE, our predicted user rating for a film is already typically less than a star from the reality. Let's use what we've learned to see how we can model by trying different algorithms and parameters.\n",
    "\n",
    "Across our trial and error models, we actually tried all the similarity metrics available in the surprise library but found the two above to give us the best results so far. They can be found __[here](https://surprise.readthedocs.io/en/stable/similarities.html)__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What do our predictions look like in real time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Prediction(uid='rbonaime', iid='the-bigger-picture', r_ui=6.0, est=6.853587940579535, details={'actual_k': 40, 'was_impossible': False}),\n",
       " Prediction(uid='allisoncm', iid='the-technique-and-the-rite', r_ui=5.0, est=6.0, details={'actual_k': 1, 'was_impossible': False}),\n",
       " Prediction(uid='joedicanio', iid='may', r_ui=7.0, est=6.605265251368509, details={'actual_k': 40, 'was_impossible': False}),\n",
       " Prediction(uid='dylanblondee', iid='22-july', r_ui=5.0, est=6.33035490908406, details={'actual_k': 40, 'was_impossible': False}),\n",
       " Prediction(uid='tubbs', iid='the-sisterhood-of-the-traveling-pants', r_ui=4.0, est=5.3535220692543914, details={'actual_k': 40, 'was_impossible': False})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output example predictions within our current model\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's predict how a particular user might rate a particular film"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'davidehrlich'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for this user\n",
    "df['user_id'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happiest-season'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for this item\n",
    "df['movie_id'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid='davidehrlich', iid='happiest-season', r_ui=None, est=6.06895844485103, details={'actual_k': 40, 'was_impossible': False})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here's our predicted rating\n",
    "algo_knn_basic.predict(df['user_id'][1], df['movie_id'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After iterating our first model, we currently predict user `davidehrlich` would rate Hulu film Happiest Season with a 6/10 aka 3 stars in the Letterboxd app. We can use these predictions to order films to serve him the recommendations that will better fit his taste. Yet, we need to keep in mind that improved accuracy will make this feature more powerful and poignant. Narratives have a special place in our society and with a database of over 250K films to recommend - let's try to further increase our accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run our second model: KNNWithMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`KNNWithMeans` is also a basic collaborative filtering algorithm, but this algorithm takes into account the mean ratings of each user. We'll see if this algorithm brings better results across the two similarity metrics that have proved most successful to date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "k = 15\n",
    "min_k = 5\n",
    "sim_options = {'name': 'pearson'}\n",
    "knn_means = KNNWithMeans(k=k, min_k=min_k, sim_options=sim_options, verbose=True)\n",
    "    \n",
    "predictions = knn_means.fit(train).test(test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESULTS**\n",
    "* RMSE: 1.5607923504104053"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the breakdown of similarity types:\n",
    "* **cosine**:\tCompute the cosine similarity between all pairs of users (or items).\n",
    "* **pearson**:\tCompute the Pearson correlation coefficient between all pairs of users (or items).\n",
    "* **msd**:\tCompute the Mean Squared Difference similarity between all pairs of users (or items).\n",
    "    \n",
    "Let's bring in our `msd` similarity since have yet to explore how that'll perform with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "k = 15\n",
    "min_k = 5\n",
    "sim_options = {'name': 'msd'}\n",
    "knn_means = KNNWithMeans(k=k, min_k=min_k, sim_options=sim_options, verbose=True)\n",
    "    \n",
    "predictions = knn_means.fit(train).test(test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESULTS**\n",
    "* RMSE 1.514157952922513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "k = 40\n",
    "min_k = 5\n",
    "sim_options = {'name': 'msd'}\n",
    "knn_means = KNNWithMeans(k=k, min_k=min_k, sim_options=sim_options, verbose=True)\n",
    "    \n",
    "predictions = knn_means.fit(train).test(test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESULTS**\n",
    "* RMSE 1.508629823133224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the `k` parameter clearly helped a bit. Now, let's see if using the similarity type that's winning so far aids the first model we tried."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A similarity iteration with our first model: KNNBasic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sim_options = {'name': 'msd'}\n",
    "algo_knn_basic = KNNBasic(sim_options=sim_options)\n",
    "predictions = algo_knn_basic.fit(train).test(test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESULTS**\n",
    "* RMSE 1.4898636221946142"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we brought the winning similarity metric from our KNNWithMeans iterations back to our first model, we clearly improved our RMSE - which previously had a record of 1.5884 (with KNNBasic) and 1.5086 (with KNNWithMeans)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run our third model: SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SVD`, or Singular Value Decomposition, was originally popularized by Simon Funk during the Netflix Prize competition (__[see Simon's breakdown of this model](https://sifter.org/simon/journal/20061211.html)__), and is now used across a variety of applications.\n",
    "\n",
    "Unlike the prior two models we tried above - this algorithm is matrix-factorization based instead of focused around the similarity metrics above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# run the default SVD model\n",
    "svd = SVD()\n",
    "svd.fit(train)\n",
    "predictions = svd.test(test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESULTS**\n",
    "* RMSE: 1.4183454579066075"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our best RMSE to date! Our model prediction results would place us within about .70 stars off from the reality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing our Default Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Surprise library has methods to help us find the best parameters for tuning our model. I ran surprise's `GridsearchCV` method across multiple quantities and factors for the SVD algorithm in the notebook titled [Gridsearch](/notebooks/gridsearch.ipynb) and extracted the best performing parameters. Let's run these new parameters on our model below and see how our accuracy changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# fit our algorithm with winning hyperparameters\n",
    "svd = SVD(lr_all=0.008, n_factors=40, reg_all=0.025, biased=True)\n",
    "svd.fit(train)\n",
    "predictions = svd.test(test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.4022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4021701605968926"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESULTS**\n",
    "* RMSE: 1.4021701605968926"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We successfully used Gridsearch to identify better parameters for our model! This is the highest RMSE we've achieved so far and the run time was under twenty minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's predict how that same user might rate the same film"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'davidehrlich'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for this user\n",
    "df['user_id'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happiest-season'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for this item\n",
    "df['movie_id'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid='davidehrlich', iid='happiest-season', r_ui=None, est=5.488776723015272, details={'was_impossible': False})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here's our predicted rating\n",
    "svd.predict(df['user_id'][1], df['movie_id'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see with greater accuracy that user `davidehrlich` is estimated to rate Hulu film Happiest Season with a 5.5 on a 10 point scale aka 2.5 stars in Letterboxd. With our first model, we predicted 2.5 stars and have gotten increasingly closer to what our user likely would've rated the film. Now, we can surface better recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "* Our final, iterated SVD model runs in about twenty minutes currently and has prediction accuracy within half a star of how a Letterboxd user tends to rate a film. Next, we'll want to create the front-end experience for a Letterboxd user to source these helpful recommendations. We could perhaps deploy this via Flask and Heroku or aim to bring into the Letterboxd app via web or iOS after testing. We'll want to ask questions to mitigate against the cold start problem and have some initial recommendations sourced in record time prior to the more personalized processing we're now capable of."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
